{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Visual Behavior Neuropixels Exercise 2: Active vs. Passive </h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Visual stimuli refresher\n",
    "\n",
    "As a reminder, every recording session consisted of three major visual stimulus epochs in the following order (diagrammed below):\n",
    "- An active behavior session during which the mouse performed the change detection task\n",
    "- Receptive field mapping and full-field flash stimuli\n",
    "- 'Passive' replay of stimulus shown during active behavior, but without the lickspout so the mouse can no longer respond.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://brainmapportal-live-4cc80a57cd6e400d854-f7fdcae.divio-media.net/filer_public_thumbnails/filer_public/65/58/6558f0eb-c3c5-45e6-b645-b2e432200804/active_passive_diagram.png__710x291_q90_subsampling-2.png\", width=\"900\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Descriptions of each stimulus block in <code>stimulus_presentations['stimulus_block']</code>\n",
    "\n",
    "**block 0**: Change detection task. Natural images are flashed repeatedly and the mouse is rewarded for licking when the identity of the image changes. You can find more info about this task [here](http://portal.brain-map.org/explore/circuits/visual-behavior-neuropixels?edit&language=en).\n",
    "\n",
    "**block 1**: Brief gray screen\n",
    "\n",
    "**block 2**: Receptive field mapping using gabor stimuli. For more details on this stimulus consult [this notebook](https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_receptive_fields.html).\n",
    "\n",
    "**block 3**: Longer gray screen\n",
    "\n",
    "**block 4**: Full-field flashes, shown at 80% contrast. Flashes can be black (color = -1) or white (color = 1).\n",
    "\n",
    "**block 5**: Passive replay. Frame-for-frame replay of the stimulus shown during the change detection task (block 0), but now with the lick spout retracted so the animal can no longer engage in the task.\n",
    "\n",
    "    \n",
    "For this exercise, we will focus on **block 0** and **block 5**, the **active behavior** and the **passive replay** of the same images.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "**Exercise 2.1: Plot neural activity from VISp averaged across Active vs. Passive image changes from one ephys session**\n",
    "\n",
    "* 2.1.1: Load an ephys session\n",
    "* 2.1.2: Load neural data\n",
    "* 2.1.3: Filter for good quality VISp units \n",
    "* 2.1.4: Find timepoints of image changes\n",
    "* 2.1.5: Align VISp activity to changes\n",
    "* 2.1.6: Find indices of Active and Passive changes\n",
    "* 2.1.7: Take the mean across units and Active vs. Passive trials\n",
    "* 2.1.8: Plot mean VISp activity for Active vs. Passive changes\n",
    "    \n",
    "Hint: we did something similar during the Tutorial, but for Novel vs. Familiar image changes\n",
    "    \n",
    "    \n",
    "Bonus: Plot baseline-subtracted Active vs. Passive change responses\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "**2.1.1: Load an ephys session**\n",
    "\n",
    "Feel free to load the same session from the tutorial. Or if you're feeling adventurous, load a different one!\n",
    "    \n",
    "Hint: First, initialize the cache. Next, load the ecephys_session_table, choose a session, and load it.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "data_dirname = 'visual-behavior-neuropixels'\n",
    "use_static = False\n",
    "if 'Darwin' in platstring or 'macOS' in platstring:\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2022/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on AWS\n",
    "    data_root = \"/data/\"\n",
    "    data_dirname = 'visual-behavior-neuropixels-data'\n",
    "    use_static = True\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2022/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.behavior.behavior_project_cache.\\\n",
    "    behavior_neuropixels_project_cache \\\n",
    "    import VisualBehaviorNeuropixelsProjectCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this path should point to the location of the dataset on your platform\n",
    "cache_dir = os.path.join(data_root, data_dirname)\n",
    "\n",
    "cache = VisualBehaviorNeuropixelsProjectCache.from_local_cache(\n",
    "            cache_dir=cache_dir, use_static_cache=use_static)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinejunhuiliu/opt/anaconda3/envs/swdb2022/lib/python3.8/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'core' version 2.4.0 because version 2.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    }
   ],
   "source": [
    "session_id = 1053941483\n",
    "session = cache.get_ecephys_session(\n",
    "            ecephys_session_id=session_id) #get all data that has the same session_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "**2.1.2: Load neural data**\n",
    "\n",
    "What do we need to load from the session object in order to plot the spiking activity of units from VISp?\n",
    "    \n",
    "Hint: we need information about what area they are in, along with information about what times they spiked.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentations = session.stimulus_presentations #this is a dataFrame\n",
    "units1 = session.get_units()\n",
    "channels = session.get_channels()\n",
    "spikes = session.spike_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit2 = units1.merge (channels, left_on = 'peak_channel_id',right_index=True)\n",
    "VISp_units = unit2[unit2.structure_acronym == 'VISp']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "**2.1.3: Filter for good quality VISp units**\n",
    "    \n",
    "Reminder: the index of the units table is the unit_id    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 34)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodVISp_units = VISp_units[(VISp_units.quality == 'good') &\n",
    "                  (VISp_units.snr > 1) &\n",
    "                  (VISp_units.isi_violations < 1)]\n",
    "goodVISp_units.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**2.1.4: Find timepoints of image changes**\n",
    "\n",
    "Hint: most stimulus presentations are not changes. Make a new table that consists of only image changes.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_stims = stimulus_presentations[stimulus_presentations['active']]\n",
    "change_stims = active_stims[active_stims.is_change==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PT_ratio', 'amplitude', 'amplitude_cutoff', 'cluster_id',\n",
       "       'cumulative_drift', 'd_prime', 'firing_rate', 'isi_violations',\n",
       "       'isolation_distance', 'l_ratio', 'local_index', 'max_drift',\n",
       "       'nn_hit_rate', 'nn_miss_rate', 'peak_channel_id', 'presence_ratio',\n",
       "       'quality', 'recovery_slope', 'repolarization_slope', 'silhouette_score',\n",
       "       'snr', 'spread', 'velocity_above', 'velocity_below',\n",
       "       'waveform_duration', 'anterior_posterior_ccf_coordinate',\n",
       "       'dorsal_ventral_ccf_coordinate', 'filtering',\n",
       "       'left_right_ccf_coordinate', 'probe_channel_number',\n",
       "       'probe_horizontal_position', 'probe_id', 'probe_vertical_position',\n",
       "       'structure_acronym'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodVISp_units.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**2.1.5: Align VISp activity to image changes**\n",
    "\n",
    "We will use the <code>makePSTH</code> and <code>make_neuron_time_trials_array</code> functions, so we should define them here or import them.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePSTH(spikes, startTimes, windowDur, binSize=0.001):\n",
    "    '''\n",
    "    Convenience function to compute a peri-stimulus-time histogram\n",
    "    (see section 7.2.2 here: https://neuronaldynamics.epfl.ch/online/Ch7.S2.html)\n",
    "    INPUTS:\n",
    "        spikes: spike times in seconds for one unit\n",
    "        startTimes: trial start times in seconds; the first spike count \n",
    "            bin will be aligned to these times\n",
    "        windowDur: trial duration in seconds\n",
    "        binSize: size of spike count bins in seconds\n",
    "    OUTPUTS:\n",
    "        Tuple of (PSTH, bins), where:\n",
    "            PSTH gives the trial-averaged spike rate for \n",
    "                each time bin aligned to the start times;\n",
    "            bins are the bin edges as defined by numpy histogram\n",
    "    '''\n",
    "    bins = np.arange(0,windowDur+binSize,binSize)\n",
    "    counts = np.zeros(bins.size-1)\n",
    "    for start in startTimes:\n",
    "        startInd = np.searchsorted(spikes, start)\n",
    "        endInd = np.searchsorted(spikes, start+windowDur)\n",
    "        counts = counts + np.histogram(spikes[startInd:endInd]-start, bins)[0]\n",
    "    \n",
    "    counts = counts/len(startTimes)\n",
    "    return counts/binSize, bins[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_neuron_time_trials_array(units, spike_times, stim_table, \n",
    "                                   time_before, trial_duration,\n",
    "                                   bin_size=0.001): #bin_size is 1 msec\n",
    "    '''\n",
    "    Function to make a 3D array with dimensions [neurons, time bins, trials] to store\n",
    "    the spike counts for stimulus presentation trials. \n",
    "    INPUTS:\n",
    "        units: dataframe with unit info (same form as session.units table)\n",
    "        stim_table: dataframe whose indices are trial ids and containing a\n",
    "            'start_time' column indicating when each trial began\n",
    "        time_before: seconds to take before each start_time in the stim_table\n",
    "        trial_duration: total time in seconds to take for each trial\n",
    "        bin_size: bin_size in seconds used to bin spike counts \n",
    "    OUTPUTS:\n",
    "        unit_array: 3D array storing spike counts. The value in [i,j,k] \n",
    "            is the spike count for neuron i at time bin j in the kth trial.\n",
    "        time_vector: vector storing the trial timestamps for the time bins\n",
    "    '''\n",
    "    # Get dimensions of output array\n",
    "    neuron_number = len(units)\n",
    "    trial_number = len(stim_table)\n",
    "    num_time_bins = int(trial_duration/bin_size)\n",
    "    \n",
    "    # Initialize array\n",
    "    unit_array = np.zeros((neuron_number, num_time_bins, trial_number))\n",
    "    \n",
    "    # Loop through units and trials and store spike counts for every time bin\n",
    "    for u_counter, (iu, unit) in enumerate(units.iterrows()):\n",
    "        \n",
    "        # grab spike times for this unit\n",
    "        unit_spike_times = spike_times[iu]\n",
    "        \n",
    "        # now loop through trials and make a PSTH for this unit for every trial\n",
    "        for t_counter, (it, trial) in enumerate(stim_table.iterrows()):\n",
    "            trial_start = trial.start_time - time_before\n",
    "            unit_array[u_counter, :, t_counter] = makePSTH(unit_spike_times, \n",
    "                                                            [trial_start], \n",
    "                                                            trial_duration, \n",
    "                                                            binSize=bin_size)[0]\n",
    "    \n",
    "    # Make the time vector that will label the time axis\n",
    "    time_vector = np.arange(num_time_bins)*bin_size - time_before\n",
    "    \n",
    "    return unit_array, time_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "**2.1.6: Find indices of Active and Passive changes**\n",
    "\n",
    "Hint: remember to use your new table of image changes, otherwise you might find the wrong indices\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "**2.1.7: Take the mean across units and Active vs. Passive trials**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "**2.1.8: Plot mean VISp activity for Active vs. Passive changes**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You should see a difference between VISp responses to Active vs. Passive changes\n",
    "* The largest difference is an overall shift in firing rate. What if we want to know whether the evoked firing rate relative to the baseline is the same or different in Active vs. Passive conditions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**Bonus: baseline-subtracted PSTHs**\n",
    "\n",
    "* If what we are interested in is the stimulus-evoked changes in firing rate, we need to correct for the baseline.\n",
    "    \n",
    "* Now, before averaging over neurons, first subtract each neuron's baseline firing rate (0.2 - 0 sec before the change).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**Exercise 2.2: Plot running and pupil area averaged across Active vs. Passive image changes from the same session**\n",
    "\n",
    "The lick spout is retracted, so mice are no longer performing behavior and there are no licks. Let's look at other measures of behavior, running and pupil size.\n",
    "    \n",
    "* 2.2.1: Get running speed and eye tracking tables\n",
    "* 2.2.2: Align running and pupil data to Active vs. Passive changes\n",
    "* 2.2.3: Average across trials\n",
    "* 2.2.4: Plot these averages\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "**2.2.1: Get runnning speed and eye tracking tables**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**2.2.2: Align running and pupil data to Active changes**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**2.2.3: Align running and pupil data to Passive changes**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**2.2.4: Average across trials and plot**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
